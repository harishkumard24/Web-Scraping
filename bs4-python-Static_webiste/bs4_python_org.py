# -*- coding: utf-8 -*-
"""bs4-python-org.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aJKaePKCfB_lWKA2_JbgcvWo86rZ6Tyi
"""

!pip install bs4

pip install requests

from bs4 import BeautifulSoup
import requests



url = 'https://www.python.org/jobs/'

page= requests.get(url)

soup= BeautifulSoup(page.text, 'html')
all_jobs = []

print(soup.prettify())

soup.find_all('ul', class_="pagination menu")

soup.find_all('ol', class_="list-recent-jobs list-row-container menu")

from bs4 import NavigableString

# Start URL
base_url = "https://www.python.org"
url = f"{base_url}/jobs/"

while url:
    page = requests.get(url)
    soup = BeautifulSoup(page.text, 'html.parser')

    # Get the jobs container
    job_list = soup.find('ol', class_="list-recent-jobs list-row-container menu")
    if not job_list:
        break

    # Find all job listings inside <li>
    jobs = job_list.find_all('li')

    # Loop through each job and extract details (your existing working code)
    for job in jobs:
        title = job.find('h2', class_='listing-company').find('a').get_text(strip=True)

        # FIXED company extraction
        company = "N/A"
        company_span = job.find('span', class_='listing-company-name')
        if company_span:
            a = company_span.find('a')
            if a:
                for sib in a.next_siblings:
                    if isinstance(sib, NavigableString) and sib.strip():
                        company = sib.strip()
                        break

        location = job.find('span', class_='listing-location').get_text(strip=True)
        job_type = job.find('span', class_='listing-job-type').get_text(strip=True)
        date_posted = job.find('span', class_='listing-posted').find('time')['datetime']
        category = job.find('span', class_='listing-company-category').get_text(strip=True)

        print(f"Title: {title}")
        print(f"Company: {company}")
        print(f"Location: {location}")
        print(f"Job Type: {job_type}")
        print(f"Date Posted: {date_posted}")
        print(f"Category: {category}")
        print("-" * 50)

        all_jobs.append({
            "Title": title,
            "Company": company,
            "Location": location,
            "Job Type": job_type,
            "Date Posted": date_posted,
            "Category": category
        })

    # Pagination: move to next page if exists
    pagination = soup.find('ul', class_='pagination menu')
    next_page = None
    if pagination:
        current_page = pagination.find('a', class_='active')
        if current_page:
            next_li = current_page.find_parent('li').find_next_sibling('li')
            if next_li and next_li.find('a') and not next_li.find('a').has_attr('class'):
                next_page = next_li.find('a')['href']

    if next_page:
        url = base_url + "/jobs/" + next_page
    else:
        url = None

import pandas as pd
from google.colab import files  # <-- Add this

# Convert scraped data to DataFrame
df = pd.DataFrame(all_jobs)

# Save to CSV
df.to_csv("python_jobs_all_pages.csv", index=False)

print(f"Total jobs saved: {len(df)}")
display(df.head())  # Optional: better table display in Colab

# Download in Colab
files.download("python_jobs_all_pages.csv")